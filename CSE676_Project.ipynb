{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as KL\n",
    "from keras import callbacks\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eaff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "dir_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be5f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels\n",
    "# img_0 - img_118 are Treble. Treble = 0\n",
    "# img_119 - img_219 are Bass. Bass = 1\n",
    "# img_220 - img_318 are Tenor. Tenor = 2\n",
    "# img_319 - img_418 are Alto. Alto = 3\n",
    "\n",
    "labels = np.empty(419,dtype=int) # Change number to 220 for Model 1. 200 for Model 2. 419 for Model 3.\n",
    "for x in range(119):\n",
    "  labels[x] = 0\n",
    "for x in range(119,220):\n",
    "  labels[x] = 1\n",
    "\n",
    "#####\n",
    "# Comment out this part for Model 1\n",
    "for x in range(220,319):\n",
    "  labels[x] = 2\n",
    "for x in range(319,419):\n",
    "  labels[x] = 3\n",
    "#####\n",
    "\n",
    "\n",
    "#####\n",
    "# This part is for Model 2\n",
    "#for x in range(100):\n",
    "#    labels[x] = 2\n",
    "#for x in range(100,200):\n",
    "#    labels[x] = 3\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath = [f'img_{n}.png' for n in range(419)] # 220 for Model 1. 200 for Model 2. 419 for Model 3.\n",
    "\n",
    "imgs = []\n",
    "maxh = 0\n",
    "maxw = 0\n",
    "for ipath in imgpath:\n",
    "  # Read in image in greyscale\n",
    "  fullpath = os.path.join(path,ipath)\n",
    "  img = cv2.imread(fullpath,0)\n",
    "\n",
    "  # Image processing\n",
    "  size = np.shape(img)\n",
    "  \n",
    "  if (size[0]>maxh):\n",
    "    maxh = size[0]\n",
    "  if (size[1]>maxw):\n",
    "    maxw = size[1]\n",
    "\n",
    "  img_new = np.zeros(shape = size)\n",
    "\n",
    "  img_new = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,61,21)\n",
    "\n",
    "  # Gaussian blur for noise reduction\n",
    "  img_gaus = cv2.GaussianBlur(img_new,(5,5),0)\n",
    "  img_gaus = np.uint8(img_gaus)\n",
    "\n",
    "  # Resize and pad so all photos are the same size\n",
    "  h = size[0]\n",
    "  w = size[1]\n",
    "  if (h>w):\n",
    "    scale = 7015/h\n",
    "    new_w = int(size[1] * scale)\n",
    "    padding = 7015 - new_w\n",
    "    padding_floor = math.floor(padding/2)\n",
    "    padding_ceil = math.ceil(padding/2)\n",
    "    resized = cv2.resize(img_gaus, (new_w,7015), interpolation = cv2.INTER_AREA)\n",
    "    img_gaus = cv2.copyMakeBorder(resized, 0, 0, padding_floor, padding_ceil, cv2.BORDER_CONSTANT, None, value = 0)\n",
    "    img_gaus = cv2.resize(img_gaus, (512,512), interpolation = cv2.INTER_AREA)\n",
    "  elif (w>h):\n",
    "    scale = 7015/w\n",
    "    new_h = int(size[0] * scale)\n",
    "    padding = 7015 - new_h\n",
    "    padding_floor = math.floor(padding/2)\n",
    "    padding_ceil = math.ceil(padding/2)\n",
    "    resized = cv2.resize(img_gaus, (7015,new_h), interpolation = cv2.INTER_AREA)\n",
    "    img_gaus = cv2.copyMakeBorder(resized, padding_floor, padding_ceil, 0, 0, cv2.BORDER_CONSTANT, None, value = 0)\n",
    "    img_gaus = cv2.resize(img_gaus, (512,512), interpolation = cv2.INTER_AREA)\n",
    "  else:\n",
    "    img_gaus = cv2.resize(img_gaus, (512,512), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "  img_gaus = np.array(img_gaus)\n",
    "  img_gaus = img_gaus.astype('float32')\n",
    "\n",
    "  imgs.append(img_gaus)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3340368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Models 1 and 3\n",
    "Xtrain = np.concatenate((imgs[0:96],imgs[119:200],imgs[220:300],imgs[319:400]),axis=0,dtype='float32') \n",
    "# ^^^ Change to imgs[0:96],imgs[119:200] only for Model 1\n",
    "ytrain = np.concatenate((labels[0:96],labels[119:200],labels[220:300],labels[319:400]),axis=0,dtype=int) \n",
    "# ^^^ Change to labels[0:96],labels[119:200] only for Model 1\n",
    "Xtest = np.concatenate((imgs[96:119],imgs[200:220],imgs[300:319],imgs[400:419]),axis=0,dtype='float32') \n",
    "# ^^^ Change to imgs[96:119],imgs[200:220] only for Model 1\n",
    "ytest = np.concatenate((labels[96:119],labels[200:220],labels[300:319],labels[400:419]),axis=0,dtype=int) \n",
    "# ^^^ Change to ((labels[96:119],labels[200:220] only for Model 1\n",
    "#####\n",
    "\n",
    "#####\n",
    "# Uncomment this for Model 2\n",
    "#Xtrain = np.concatenate((imgs[0:80],imgs[100:181]),axis=0,dtype='float32') #imgs[0:96],imgs[119:200],imgs[220:300],imgs[319:400]\n",
    "#ytrain = np.concatenate((labels[0:80],labels[100:181]),axis=0,dtype=int) #labels[0:96],labels[119:200],labels[220:300],labels[319:400]\n",
    "#Xtest = np.concatenate((imgs[80:100],imgs[181:200]),axis=0,dtype='float32') #imgs[96:119],imgs[200:220],imgs[300:319],imgs[400:419]\n",
    "#ytest = np.concatenate((labels[80:100],labels[181:200]),axis=0,dtype=int) #labels[96:119],labels[200:220],labels[300:319],labels[400:419]\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the layers\n",
    "inputs = KL.Input(shape=(512, 512))\n",
    "l = KL.Flatten()(inputs) \n",
    "# Dense Layers: https://keras.io/api/layers/core_layers/dense/   \n",
    "l = KL.Dense(512, activation=tf.nn.relu)(l) # Relu activation function\n",
    "outputs = KL.Dense(10, activation=tf.nn.softmax)(l) # softmax activation function\n",
    "\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "#earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", mode = \"min\", patience = 5, restore_best_weights = True)\n",
    "\n",
    "# For compile/fit args: https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"]) # sparse bc labels as ints\n",
    "history = model.fit(Xtrain, ytrain, epochs=100, validation_data=(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  For history and plotting https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
